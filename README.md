## üñºÔ∏è 1. An√°lisis de Sentimientos por Im√°genes con MediaPipe, Hilos, Mutex y Sem√°foros

Este componente implementa un sistema de clasificaci√≥n de **emociones b√°sicas** (feliz, triste, enojado) a partir de im√°genes faciales. Para la detecci√≥n y extracci√≥n de caracter√≠sticas, se utiliza la librer√≠a **MediaPipe Face Mesh**.

El procesamiento es **paralelo**, donde cada imagen se analiza en un **hilo independiente**, y el acceso a recursos compartidos se sincroniza mediante `Lock` y `Semaphore`.

---

### üéØ Objetivo de la Secci√≥n

Desarrollar un sistema concurrente capaz de:

1.  **Detectar rostros** en im√°genes usando **MediaPipe Face Mesh**.
2.  **Extraer *landmarks*** faciales relevantes (puntos clave). 
3.  **Inferir el sentimiento** (feliz, triste, enojado) utilizando reglas geom√©tricas simples basadas en los *landmarks* extra√≠dos.
4.  **Procesar m√∫ltiples im√°genes simult√°neamente** mediante hilos para optimizar el rendimiento.

| Mecanismo de Concurrencia | Prop√≥sito |
| :--- | :--- |
| **Hilos** (`threading.Thread`) | Procesamiento de cada imagen en paralelo. |
| **Mutex** (`Lock`) | Proteger la estructura de resultados compartida. |
| **Sem√°foro** (`Semaphore`) | Limitar el n√∫mero de im√°genes procesadas al mismo tiempo, controlando la carga del sistema. |

### ‚öôÔ∏è Instalaci√≥n y Ejecuci√≥n

Las dependencias principales para este entregable son
- opencv-python
- mediapipe
- numpy


## Esquema de Procesamiento Paralelo

| Etapa 1: Entrada | Etapa 2: Procesamiento (Hilos Paralelos) | Etapa 3: Salida Unificada |
| :---: | :---: | :---: |
| **[Imagen A]** | $\rightarrow$ **[Hilo 1]** | \ |
| **[Imagen B]** | $\rightarrow$ **[Hilo 2]** | $\rightarrow$ **[Resultados finales protegidos con Lock]** |
| **[Imagen C]** | $\rightarrow$ **[Hilo 3]** | / |

---
### üß† L√≥gica del Procesamiento

La clasificaci√≥n de emociones se basa en el an√°lisis de *landmarks* faciales extra√≠dos por MediaPipe, siguiendo una serie de pasos concurrentes:

---

- #### 1. Detecci√≥n del Rostro

Se utiliza la soluci√≥n de **MediaPipe Face Mesh** para identificar la posici√≥n y los 468 *landmarks* (puntos clave) del rostro en la imagen:

```bash
mp.solutions.face_mesh.FaceMesh
```
-Regla de Salida: Si el proceso no detecta un rostro en la imagen de entrada, el resultado inmediato es: ‚ÄúSIN ROSTRO DETECTADO‚Äù.

- #### 2. Landmarks Utilizados para Clasificaci√≥n

Para inferir la emoci√≥n, el sistema se enfoca en las m√©tricas geom√©tricas de las siguientes √°reas faciales, ya que son las m√°s expresivas de las emociones b√°sicas:

    Comisuras de la boca

    Apertura y curvatura de la boca

    √Ångulo de inclinaci√≥n de las cejas

    Relaci√≥n vertical entre los labios
    
#### 3. Reglas de Sentimientos (Clasificaci√≥n B√°sica)

La inferencia de la emoci√≥n se realiza aplicando **reglas geom√©tricas simples** (umbrales) sobre los *landmarks* extra√≠dos.

| Emoci√≥n | Patr√≥n Geom√©trico (Resumen) |
| :--- | :--- |
| **Feliz** | Boca m√°s ancha que alta, con **comisuras elevadas** (arqueadas hacia arriba). |
| **Triste** | Boca angosta y **comisuras ca√≠das** (arqueadas hacia abajo). |
| **Enojado** | **Ojos entrecerrados** y **cejas inclinadas** hacia el centro (fruncidas). |


- ### üßµ Concurrencia Implementada

Los mecanismos de concurrencia aseguran que el an√°lisis intensivo de im√°genes (MediaPipe) se ejecute de forma **paralela y segura**. 

| Mecanismo | C√≥digo de Implementaci√≥n | Funci√≥n |
| :--- | :--- | :--- |
| **‚úî Creaci√≥n de Hilos** | `t = threading.Thread(target=procesar_imagen, args=(ruta,))`<br>`t.start()` | Cada imagen de entrada lanza un **hilo independiente** para su procesamiento. |
| **‚úî Sem√°foro** | `semaforo = Semaphore(2)` | Limita el procesamiento a un m√°ximo de **2 hilos** (im√°genes) simult√°neamente, evitando la saturaci√≥n del sistema. |
| **‚úî Mutex** | `with lock:`<br>`resultados[ruta] = emocion` | Protege el **diccionario de resultados** (`resultados`), previniendo que m√∫ltiples hilos escriban o corrompan los datos al mismo tiempo (**condici√≥n de carrera**). |

####  Ejecuci√≥n

Para iniciar la aplicaci√≥n 
```bash
python "nombre".py
```
(Se deben tener preparadas las imagenes dentro de la carpeta para que logre procesarlas)

- #### üìä Ejemplo de Salida

```bash
Imagen_feliz.jpg   ‚Üí   Feliz
rostro_3.jpg       ‚Üí   Enojado
selfie.png         ‚Üí   SIN ROSTRO DETECTADO
```

- #### ‚úî Estado final de la secci√≥n

La soluci√≥n completa incluye:

Procesamiento por hilos ‚úî

Uso de sem√°foro ‚úî

Protecci√≥n con mutex ‚úî

MediaPipe para detecci√≥n facial ‚úî

Clasificaci√≥n de tres emociones (feliz, triste, enojado) ‚úî

---

![Image](https://github.com/user-attachments/assets/22ef69cf-dfdb-4cf8-b313-75174b84a129)

![Image](https://github.com/user-attachments/assets/fc167f04-2245-4811-a680-85c0e4c9023f)


---

## 2) üìò Desarrollo de un ETL partiendo de una base de datos

---

### üéØ Objetivo del Punto 2

El objetivo es desarrollar un pipeline ETL funcional, entrenar un modelo simple y desplegar un dashboard interactivo en Streamlit, integrando diferentes conceptos del curso.

Espec√≠ficamente, se busca:

* Desarrollar un **ETL completo** a partir de la base de datos proporcionada en clase (o datos sint√©ticos en caso de ausencia).
* Aplicar **transformaciones**, generar un dataset procesado.
* Construir un **dashboard con Streamlit** que visualice la informaci√≥n obtenida y los resultados del modelo.

#### Conceptos Integrados

Este punto integra y refuerza conceptos clave vistos a lo largo del laboratorio:

* Terminal de **Ubuntu Linux**
* **Concurrencia / hilos / sem√°foros**
* **Seguridad en la red** (nmap, lynis)
* **Entornos virtuales** (`venv`)
* **Docker** para despliegue
* Uso de librer√≠as como Mediapipe y PyBullet (conceptos relacionados a visi√≥n/simulaci√≥n)
* **Arquitectura modular** en Python

---

### üìå Descripci√≥n del Trabajo Realizado

Durante este punto del laboratorio se desarroll√≥ una soluci√≥n modular, compuesta por un pipeline de datos y una capa de visualizaci√≥n:

#### ‚úî 1. Un Pipeline ETL Completo

El pipeline se divide en tres m√≥dulos esenciales para el procesamiento de datos:

| M√≥dulo | Funci√≥n | Descripci√≥n |
| :--- | :--- | :--- |
| **`extract`** | **Carga de Datos** | Carga de datos desde archivos fuente (Excel/CSV) o generaci√≥n de datos sint√©ticos. |
| **`transform`** | **Limpieza y Normalizaci√≥n** | Aplicaci√≥n de reglas de negocio, limpieza de *outliers* y normalizaci√≥n de variables. |
| **`load`** | **Exportaci√≥n** | Exportaci√≥n del dataset transformado a un archivo `procesado.csv` para su uso posterior. |

El ETL se ejecuta mediante el siguiente comando:

```bash
python3 etl_pipeline.py
```

**‚úî 2. Entrenamiento de un modelo b√°sico**

Utilizando redes neuronales con Keras/TensorFlow:

- Normalizaci√≥n MinMaxScaler

- Red sencilla (64‚Äì32‚Äì1)

- Entrenamiento supervisado

- Guardado del modelo en model/modelo_exportado.h5

Se ejecuta con:

```bash
python3 model/train_model.py
```
**‚úî 3. Creaci√≥n del Dashboard en Streamlit**

El dashboard:

- Muestra el dataset procesado

- Genera un mapa de correlaci√≥n

- Permite visualizar distribuciones

- Carga el modelo entrenado

- Realiza predicciones sobre filas del dataset

El dashboard se ejecuta con:
```bash
streamlit run dashboard/app.py
```

### üß† Conceptos aplicados
---

**üü¶ Ubuntu Linux**

- Terminal, rutas absolutas y relativas

- Manejo de entornos virtuales

- Ejecuci√≥n de scripts Python

- Instalaci√≥n de librer√≠as del laboratorio

**üüß ETL**

- Separaci√≥n en m√≥dulos: extract, transform, load

- Manejo de errores (archivos corruptos, rutas inv√°lidas)

- Consolidaci√≥n en procesado.csv

**üü® Concurrencia, hilos y sem√°foros**

- Aunque no se aplican directamente al ETL, s√≠ se integran en:

- Manejo de carga de modelo

**üü• Seguridad en la red**
```bash
nmap -sV localhost
sudo lynis audit system
```
Aplicadas para:

- Evaluar seguridad del contenedor

- Revisar puertos expuestos del dashboard

**üü™ Docker**

- Se prepar√≥ un Dockerfile para permitir:

- Instalar dependencias

- Ejecutar ETL, modelo y dashboard dentro de un contenedor

**üü© Machine Learning**

- Red neuronal artificial

- Normalizaci√≥n

- Entrenamiento supervisado

- Predicci√≥n desde el dashboard

**üü´ Mediapipe / PyBullet**

- Aunque no se usan directamente en el ETL, se relacionan con:

- Manejo de grandes vol√∫menes de datos sensoriales

- Comprensi√≥n de se√±ales biomec√°nicas

- Aplicaciones del curso

- Lectura concurrente de archivos (concepto discutido)

- Estructura del dashboard

---

### üìÇ Estructura del directorio

Descripci√≥n de M√≥dulos

    - data/

        BD_COMPLETA.xlsx: Base de datos original (opcional).

        sensores_base.csv: Datos base (Generados sint√©ticamente).

        procesado.csv: Dataset limpio y transformado (Salida del ETL).

    - etl/

        extract.py: M√≥dulo de Extracci√≥n (Carga de datos).

        transform.py: M√≥dulo de Transformaci√≥n (Limpieza y normalizaci√≥n).

        load.py: M√≥dulo de Carga (Exporta a procesado.csv).

        run_etl.py: Script principal de ejecuci√≥n del pipeline.

    - model/

        train_model.py: Script para el entrenamiento del modelo.

        predict_model.py: Script para predicciones.

        modelo_exportado.h5: Modelo entrenado y serializado.

    - dashboard/

        app.py: Dashboard interactivo con Streamlit (Punto 2).

    - tools/

        gen_synthetic.py: Script para generar datos sint√©ticos.
---

## üöÄ Procedimiento paso a paso

- 1Ô∏è‚É£ Crear entorno virtual

```bash
python3 -m venv venv
source venv/bin/activate
```

- 2Ô∏è‚É£ Instalar dependencias

```bash
    pip install -r requirements.txt
```

- 3Ô∏è‚É£ Generar datos sint√©ticos (opcional)

```bash
    python3 tools/gen_synthetic.py
```

- 4Ô∏è‚É£ Ejecutar ETL completo

```bash
    python3 etl/run_etl.py
```
Se genera:
```bash
    data/procesado.csv
```

- 5Ô∏è‚É£ Entrenar el modelo
```bash
    python3 model/train_model.py
```
Se genera:
```bash
    model/modelo_exportado.h5
```
- 6Ô∏è‚É£ Ejecutar dashboard
```bash
    streamlit run dashboard/app.py
```

### üìä Resultados esperados

- Archivo procesado.csv generado correctamente

- Modelo entrenado disponible

- Dashboard con:

    - visualizaci√≥n de la base procesada

    - mapa de correlaci√≥n

    - histogramas

    - predicci√≥n con modelo neuronal

### üß™ Validaci√≥n adicional 

Ver puertos expuestos:
```bash
    nmap -sV localhost
```

Auditor√≠a del sistema:
```bash
    sudo lynis audit system
```
--- 

# üê≥ Dockerizaci√≥n

Se realiz√≥ la **dockerizaci√≥n** del **ETL**, el **modelo** y el **dashboard** para garantizar **portabilidad**, **reproducibilidad** y **despliegue independiente** del sistema operativo.

A continuaci√≥n se describe el proceso realizado.

---

### üìå 1. Creaci√≥n del Dockerfile

Se cre√≥ un archivo `Dockerfile` en el directorio ra√≠z del proyecto.

### ¬øQu√© hace este Dockerfile?

* Utiliza una **imagen ligera** (`python:3.12-slim`).
* Copia **todo el proyecto** al contenedor.
* Instala **dependencias** sin utilizar cach√©.
* Expone el **puerto 8501** (donde corre Streamlit).
* Arranca directamente el **Dashboard** al iniciar el contenedor.

###  2. Construcci√≥n de la imagen

Desde la carpeta ra√≠z del proyecto:

```bash
    docker build -t stc_lab7 .
```
Donde:

- stc_lab7 es el nombre de la imagen resultante.

Esto genera una imagen autosuficiente que contiene:

- ETL

- Modelo

- Dashboard

- Dependencias de Python

-  3. Ejecuci√≥n del contenedor

Para ejecutar el dashboard desde Docker

```bash
    docker run -p 8501:8501 stc_lab7
```
Descripci√≥n:

- -p 8501:8501 expone el puerto del contenedor al host

- El dashboard queda disponible en:
    ```bash
    http://localhost:8501
    ```
    
###  4. Verificaci√≥n del despliegue

Despu√©s de levantar el contenedor:

‚úî Ver puertos activos con nmap
  ```bash
    nmap -sV localhost
   ```

Debe aparecer:
 ```bash
    8501/tcp open http streamlit
 ```
    
‚úî Auditor√≠a de seguridad opcional con lynix
  ```bash
sudo lynis audit system
  ```

- Esto valida:

    - dependencias del contenedor

    - puertos expuestos

    - vulnerabilidades conocidas


