# üñºÔ∏è 1. An√°lisis de Sentimientos por Im√°genes con MediaPipe, Hilos, Mutex y Sem√°foros

Este componente implementa un sistema de clasificaci√≥n de **emociones b√°sicas** (feliz, triste, enojado) a partir de im√°genes faciales. Para la detecci√≥n y extracci√≥n de caracter√≠sticas, se utiliza la librer√≠a **MediaPipe Face Mesh**.

El procesamiento es **paralelo**, donde cada imagen se analiza en un **hilo independiente**, y el acceso a recursos compartidos se sincroniza mediante `Lock` y `Semaphore`.

---

### üéØ Objetivo de la Secci√≥n

Desarrollar un sistema concurrente capaz de:

1.  **Detectar rostros** en im√°genes usando **MediaPipe Face Mesh**.
2.  **Extraer *landmarks*** faciales relevantes (puntos clave). 
3.  **Inferir el sentimiento** (feliz, triste, enojado) utilizando reglas geom√©tricas simples basadas en los *landmarks* extra√≠dos.
4.  **Procesar m√∫ltiples im√°genes simult√°neamente** mediante hilos para optimizar el rendimiento.

| Mecanismo de Concurrencia | Prop√≥sito |
| :--- | :--- |
| **Hilos** (`threading.Thread`) | Procesamiento de cada imagen en paralelo. |
| **Mutex** (`Lock`) | Proteger la estructura de resultados compartida. |
| **Sem√°foro** (`Semaphore`) | Limitar el n√∫mero de im√°genes procesadas al mismo tiempo, controlando la carga del sistema. |

### ‚öôÔ∏è Instalaci√≥n y Ejecuci√≥n

Las dependencias principales para este entregable son
- opencv-python
- mediapipe
- numpy


## Esquema de Procesamiento Paralelo

| Etapa 1: Entrada | Etapa 2: Procesamiento (Hilos Paralelos) | Etapa 3: Salida Unificada |
| :---: | :---: | :---: |
| **[Imagen A]** | $\rightarrow$ **[Hilo 1]** | \ |
| **[Imagen B]** | $\rightarrow$ **[Hilo 2]** | $\rightarrow$ **[Resultados finales protegidos con Lock]** |
| **[Imagen C]** | $\rightarrow$ **[Hilo 3]** | / |

---
### üß† L√≥gica del Procesamiento

La clasificaci√≥n de emociones se basa en el an√°lisis de *landmarks* faciales extra√≠dos por MediaPipe, siguiendo una serie de pasos concurrentes:

---

- #### 1. Detecci√≥n del Rostro

Se utiliza la soluci√≥n de **MediaPipe Face Mesh** para identificar la posici√≥n y los 468 *landmarks* (puntos clave) del rostro en la imagen:

```bash
mp.solutions.face_mesh.FaceMesh
```
-Regla de Salida: Si el proceso no detecta un rostro en la imagen de entrada, el resultado inmediato es: ‚ÄúSIN ROSTRO DETECTADO‚Äù.

- #### 2. Landmarks Utilizados para Clasificaci√≥n

Para inferir la emoci√≥n, el sistema se enfoca en las m√©tricas geom√©tricas de las siguientes √°reas faciales, ya que son las m√°s expresivas de las emociones b√°sicas:

    Comisuras de la boca

    Apertura y curvatura de la boca

    √Ångulo de inclinaci√≥n de las cejas

    Relaci√≥n vertical entre los labios
    
#### 3. Reglas de Sentimientos (Clasificaci√≥n B√°sica)

La inferencia de la emoci√≥n se realiza aplicando **reglas geom√©tricas simples** (umbrales) sobre los *landmarks* extra√≠dos.

| Emoci√≥n | Patr√≥n Geom√©trico (Resumen) |
| :--- | :--- |
| **Feliz** | Boca m√°s ancha que alta, con **comisuras elevadas** (arqueadas hacia arriba). |
| **Triste** | Boca angosta y **comisuras ca√≠das** (arqueadas hacia abajo). |
| **Enojado** | **Ojos entrecerrados** y **cejas inclinadas** hacia el centro (fruncidas). |


- ### üßµ Concurrencia Implementada

Los mecanismos de concurrencia aseguran que el an√°lisis intensivo de im√°genes (MediaPipe) se ejecute de forma **paralela y segura**. 

| Mecanismo | C√≥digo de Implementaci√≥n | Funci√≥n |
| :--- | :--- | :--- |
| **‚úî Creaci√≥n de Hilos** | `t = threading.Thread(target=procesar_imagen, args=(ruta,))`<br>`t.start()` | Cada imagen de entrada lanza un **hilo independiente** para su procesamiento. |
| **‚úî Sem√°foro** | `semaforo = Semaphore(2)` | Limita el procesamiento a un m√°ximo de **2 hilos** (im√°genes) simult√°neamente, evitando la saturaci√≥n del sistema. |
| **‚úî Mutex** | `with lock:`<br>`resultados[ruta] = emocion` | Protege el **diccionario de resultados** (`resultados`), previniendo que m√∫ltiples hilos escriban o corrompan los datos al mismo tiempo (**condici√≥n de carrera**). |

####  Ejecuci√≥n

Para iniciar la aplicaci√≥n 
```bash
python "nombre".py
```
(Se deben tener preparadas las imagenes dentro de la carpeta para que logre procesarlas)

- #### üìä Ejemplo de Salida

```bash
Imagen_feliz.jpg   ‚Üí   Feliz
rostro_3.jpg       ‚Üí   Enojado
selfie.png         ‚Üí   SIN ROSTRO DETECTADO
```

- #### ‚úî Estado final de la secci√≥n

La soluci√≥n completa incluye:

Procesamiento por hilos ‚úî

Uso de sem√°foro ‚úî

Protecci√≥n con mutex ‚úî

MediaPipe para detecci√≥n facial ‚úî

Clasificaci√≥n de tres emociones (feliz, triste, enojado) ‚úî

---

![Image](https://github.com/user-attachments/assets/22ef69cf-dfdb-4cf8-b313-75174b84a129)

![Image](https://github.com/user-attachments/assets/fc167f04-2245-4811-a680-85c0e4c9023f)


---

# 2) üìò Desarrollo de un ETL partiendo de una base de datos

---

### üéØ Objetivo del Punto 2

El objetivo es desarrollar un pipeline ETL funcional, entrenar un modelo simple y desplegar un dashboard interactivo en Streamlit, integrando diferentes conceptos del curso.

Espec√≠ficamente, se busca:

* Desarrollar un **ETL completo** a partir de la base de datos proporcionada en clase (o datos sint√©ticos en caso de ausencia).
* Aplicar **transformaciones**, generar un dataset procesado.
* Construir un **dashboard con Streamlit** que visualice la informaci√≥n obtenida y los resultados del modelo.
  
### üìä Descripci√≥n del Dashboard (Resumen Funcional)

- El dashboard desarrollado en este punto ofrece una interfaz interactiva que permite visualizar y analizar los datos resultantes del proceso ETL. Entre sus funcionalidades principales se encuentran:

    - Visualizaci√≥n del dataset procesado: muestra las primeras filas del archivo procesado.csv, permitiendo revisar el estado final de los datos despu√©s de la limpieza y transformaci√≥n.

    - Mapa de correlaci√≥n: genera una matriz gr√°fica interactiva que permite identificar relaciones entre las variables num√©ricas del conjunto de datos.

    - Exploraci√≥n de distribuciones: ofrece la posibilidad de seleccionar cualquier variable num√©rica y visualizar su distribuci√≥n mediante un histograma.

    - Predicci√≥n con el modelo entrenado: permite cargar autom√°ticamente el modelo generado en el entrenamiento y realizar una predicci√≥n utilizando la primera fila del dataset, mostrando el valor calculado en la interfaz         lateral.

    - Indicadores de estado: el dashboard valida la presencia del dataset procesado y del modelo entrenado, mostrando advertencias si alguno de ellos no est√° disponible.

    - Este panel integra de forma pr√°ctica el resultado del ETL, el modelo de predicci√≥n y las herramientas de visualizaci√≥n, permitiendo analizar el comportamiento del sistema STC de manera clara e interactiva.


#### Conceptos Integrados

Este punto integra y refuerza conceptos clave vistos a lo largo del laboratorio:

* Terminal de **Ubuntu Linux**
* **Concurrencia / hilos / sem√°foros**
* **Seguridad en la red** (nmap, lynis)
* **Entornos virtuales** (`venv`)
* **Docker** para despliegue
* Uso de librer√≠as como Mediapipe y PyBullet (conceptos relacionados a visi√≥n/simulaci√≥n)
* **Arquitectura modular** en Python

---

### üìå Descripci√≥n del Trabajo Realizado

Durante este punto del laboratorio se desarroll√≥ una soluci√≥n modular, compuesta por un pipeline de datos y una capa de visualizaci√≥n:

## üßπ Explicaci√≥n Detallada del Proceso ETL Realizado

Este apartado responde a la pregunta del profesor sobre **‚Äúqu√© se hizo con los datos, c√≥mo se limpiaron y qu√© criterios se aplicaron en el procesamiento‚Äù**.

---

### 1. ¬øQu√© datos conten√≠a la base original?

La base de datos (archivo Excel de la tesis **‚ÄúS√≠ndrome de T√∫nel Carpiano‚Äù**) conten√≠a:

* **Se√±ales capturadas por sensores** (EMG, fuerza, aceler√≥metros, etc.).
* Informaci√≥n de **participantes**.
* Registros por **ensayo**.
* **Tiempos y valores** por cada movimiento.
* **Etiquetas** del experimento (**normal / patol√≥gico**).

> El archivo estaba dividido en **varias hojas** y ten√≠a **formatos no uniformes**.

---

## üìå 2. Principales problemas encontrados en la base de datos cruda

Durante la implementaci√≥n del ETL se identificaron varios *issues* t√≠picos:

* **‚ùå Formato inconsistente**
    * Algunas hojas ten√≠an encabezados distintos.
    * Los nombres de columnas no segu√≠an un mismo patr√≥n.
* **‚ùå Valores nulos o incompletos (`NaN`)**
    * En varias columnas de se√±ales aparec√≠an celdas vac√≠as.
    * Registros incompletos por fallas en el sensor.
* **‚ùå Variables irrelevantes**
    * Hab√≠a columnas que no aportaban al an√°lisis (comentarios, c√≥digos internos, *timestamps* redundantes).
* **‚ùå Datos num√©ricos sin normalizar**
    * Rango de sensores distinto entre pruebas.
    * Se√±ales sin escalar: **imped√≠an modelos de ML**.

---

## üìå 3. E ‚Äî Extract (Extracci√≥n)

El script de ETL realiz√≥ los siguientes pasos de extracci√≥n:

1.  **Ley√≥ todas las hojas del Excel** usando `pandas.read_excel()`.
2.  **Unific√≥** los *datasets* en un solo `DataFrame`.
3.  **Extrajo √∫nicamente las columnas relevantes**:
    * Se√±ales fisiol√≥gicas
    * Fuerzas y aceleraciones
    * Etiqueta (diagn√≥stico)
    * ID del paciente

> Se construy√≥ un solo *dataset* maestro llamado **`bd_completa`**.

## üìå 4. T ‚Äî Transform (Transformaci√≥n)

Las transformaciones aplicadas fueron:

- ‚úî Limpieza de filas vac√≠as
```bash
df = df.dropna()
```
- ‚úî Correcci√≥n de tipos de datos

    - Se forz√≥ a float32 todas las columnas de se√±ales.

    - Se eliminaron columnas con strings innecesarios.

- ‚úî Normalizaci√≥n MinMax por sensor

    - Esto es esencial para modelos neuronales:
```bash
scaler = MinMaxScaler()
df[numericas] = scaler.fit_transform(df[numericas])
```
- ‚úî Renombrado coherente de columnas

    - Para evitar errores posteriores en el modelo.

- ‚úî Eliminaci√≥n de duplicados
```bash
df = df.drop_duplicates()
```
- ‚úî Creaci√≥n de una columna de √≠ndice normalizado

    - Facilita el acceso desde el dashboard.

## üìå 5. L ‚Äî Load (Carga)

Finalmente, el ETL gener√≥:
```bash
data/procesado.csv
```

- Este archivo es:

    - Limpio

    - Normalizado

    - Cohesivo

    - Consistente en nombres y tipos

    - Sin duplicados

    - Listo para an√°lisis y para alimentar el modelo neuronal

El dashboard de Streamlit lo usa directamente.


#### ‚úî 1. Un Pipeline ETL Completo

El pipeline se divide en tres m√≥dulos esenciales para el procesamiento de datos:

| M√≥dulo | Funci√≥n | Descripci√≥n |
| :--- | :--- | :--- |
| **`extract`** | **Carga de Datos** | Carga de datos desde archivos fuente (Excel/CSV) o generaci√≥n de datos sint√©ticos. |
| **`transform`** | **Limpieza y Normalizaci√≥n** | Aplicaci√≥n de reglas de negocio, limpieza de *outliers* y normalizaci√≥n de variables. |
| **`load`** | **Exportaci√≥n** | Exportaci√≥n del dataset transformado a un archivo `procesado.csv` para su uso posterior. |

El ETL se ejecuta mediante el siguiente comando:

```bash
python3 etl_pipeline.py
```

**‚úî 2. Entrenamiento de un modelo b√°sico**

Utilizando redes neuronales con Keras/TensorFlow:

- Normalizaci√≥n MinMaxScaler

- Red sencilla (64‚Äì32‚Äì1)

- Entrenamiento supervisado

- Guardado del modelo en model/modelo_exportado.h5

Se ejecuta con:

```bash
python3 model/train_model.py
```
**‚úî 3. Creaci√≥n del Dashboard en Streamlit**

El dashboard:

- Muestra el dataset procesado

- Genera un mapa de correlaci√≥n

- Permite visualizar distribuciones

- Carga el modelo entrenado

- Realiza predicciones sobre filas del dataset

El dashboard se ejecuta con:
```bash
streamlit run dashboard/app.py
```

### üß† Conceptos aplicados
---

**üü¶ Ubuntu Linux**

- Terminal, rutas absolutas y relativas

- Manejo de entornos virtuales

- Ejecuci√≥n de scripts Python

- Instalaci√≥n de librer√≠as del laboratorio

**üüß ETL**

- Separaci√≥n en m√≥dulos: extract, transform, load

- Manejo de errores (archivos corruptos, rutas inv√°lidas)

- Consolidaci√≥n en procesado.csv

**üü® Concurrencia, hilos y sem√°foros**

- Aunque no se aplican directamente al ETL, s√≠ se integran en:

- Manejo de carga de modelo

**üü• Seguridad en la red**
```bash
nmap -sV localhost
sudo lynis audit system
```
Aplicadas para:

- Evaluar seguridad del contenedor

- Revisar puertos expuestos del dashboard

**üü™ Docker**

- Se prepar√≥ un Dockerfile para permitir:

- Instalar dependencias

- Ejecutar ETL, modelo y dashboard dentro de un contenedor

**üü© Machine Learning**

- Red neuronal artificial

- Normalizaci√≥n

- Entrenamiento supervisado

- Predicci√≥n desde el dashboard

**üü´ Mediapipe / PyBullet**

- Aunque no se usan directamente en el ETL, se relacionan con:

- Manejo de grandes vol√∫menes de datos sensoriales

- Comprensi√≥n de se√±ales biomec√°nicas

- Aplicaciones del curso

- Lectura concurrente de archivos (concepto discutido)

- Estructura del dashboard

---

### üìÇ Estructura del directorio

Descripci√≥n de M√≥dulos

    - data/

        BD_COMPLETA.xlsx: Base de datos original (opcional).

        sensores_base.csv: Datos base (Generados sint√©ticamente).

        procesado.csv: Dataset limpio y transformado (Salida del ETL).

    - etl/

        extract.py: M√≥dulo de Extracci√≥n (Carga de datos).

        transform.py: M√≥dulo de Transformaci√≥n (Limpieza y normalizaci√≥n).

        load.py: M√≥dulo de Carga (Exporta a procesado.csv).

        run_etl.py: Script principal de ejecuci√≥n del pipeline.

    - model/

        train_model.py: Script para el entrenamiento del modelo.

        predict_model.py: Script para predicciones.

        modelo_exportado.h5: Modelo entrenado y serializado.

    - dashboard/

        app.py: Dashboard interactivo con Streamlit (Punto 2).

    - tools/

        gen_synthetic.py: Script para generar datos sint√©ticos.
---

## üöÄ Procedimiento paso a paso

- 1Ô∏è‚É£ Crear entorno virtual

```bash
python3 -m venv venv
source venv/bin/activate
```

- 2Ô∏è‚É£ Instalar dependencias

```bash
    pip install -r requirements.txt
```

- 3Ô∏è‚É£ Generar datos sint√©ticos (opcional)

```bash
    python3 tools/gen_synthetic.py
```

- 4Ô∏è‚É£ Ejecutar ETL completo

```bash
    python3 etl/run_etl.py
```
Se genera:
```bash
    data/procesado.csv
```

- 5Ô∏è‚É£ Entrenar el modelo
```bash
    python3 model/train_model.py
```
Se genera:
```bash
    model/modelo_exportado.h5
```
- 6Ô∏è‚É£ Ejecutar dashboard
```bash
    streamlit run dashboard/app.py
```

### üìä Resultados esperados

- Archivo procesado.csv generado correctamente

- Modelo entrenado disponible

- Dashboard con:

    - visualizaci√≥n de la base procesada

    - mapa de correlaci√≥n

    - histogramas

    - predicci√≥n con modelo neuronal

### üß™ Validaci√≥n adicional 

Ver puertos expuestos:
```bash
    nmap -sV localhost
```

Auditor√≠a del sistema:
```bash
    sudo lynis audit system
```
--- 

# üê≥ Dockerizaci√≥n

Se realiz√≥ la **dockerizaci√≥n** del **ETL**, el **modelo** y el **dashboard** para garantizar **portabilidad**, **reproducibilidad** y **despliegue independiente** del sistema operativo.

A continuaci√≥n se describe el proceso realizado.

---

### üìå 1. Creaci√≥n del Dockerfile

Se cre√≥ un archivo `Dockerfile` en el directorio ra√≠z del proyecto.

### ¬øQu√© hace este Dockerfile?

* Utiliza una **imagen ligera** (`python:3.12-slim`).
* Copia **todo el proyecto** al contenedor.
* Instala **dependencias** sin utilizar cach√©.
* Expone el **puerto 8501** (donde corre Streamlit).
* Arranca directamente el **Dashboard** al iniciar el contenedor.

###  2. Construcci√≥n de la imagen

Desde la carpeta ra√≠z del proyecto:

```bash
    docker build -t stc_lab7 .
```
Donde:

- stc_lab7 es el nombre de la imagen resultante.

Esto genera una imagen autosuficiente que contiene:

- ETL

- Modelo

- Dashboard

- Dependencias de Python

-  3. Ejecuci√≥n del contenedor

Para ejecutar el dashboard desde Docker

```bash
    docker run -p 8501:8501 stc_lab7
```
Descripci√≥n:

- -p 8501:8501 expone el puerto del contenedor al host

- El dashboard queda disponible en:
    ```bash
    http://localhost:8501
    ```
    
###  4. Verificaci√≥n del despliegue

Despu√©s de levantar el contenedor:

‚úî Ver puertos activos con nmap
  ```bash
    nmap -sV localhost
   ```

Debe aparecer:
 ```bash
    8501/tcp open http streamlit
 ```
    
‚úî Auditor√≠a de seguridad opcional con lynix
  ```bash
sudo lynis audit system
  ```

- Esto valida:

    - dependencias del contenedor

    - puertos expuestos

    - vulnerabilidades conocidas

--- 

![Image](https://github.com/user-attachments/assets/86ae9d71-2f22-4654-a537-7bd19c0706f5)

![Image](https://github.com/user-attachments/assets/4b555cdf-5e0a-4aa6-b504-0ecd36eadbba)

![Image](https://github.com/user-attachments/assets/24a32a3c-eba4-4868-adf3-b549920acd65)

![Image](https://github.com/user-attachments/assets/4b6b32cc-e72a-4871-9d68-f62025598b45)

![Image](https://github.com/user-attachments/assets/7cf7f106-0c90-4d19-b969-b73633a8f523)

![Image](https://github.com/user-attachments/assets/502d65a6-a3af-4552-ba56-ef0e6c926db4)

![Image](https://github.com/user-attachments/assets/6ad58cea-81cf-4d2e-ad3d-2adc54db6886)

![Image](https://github.com/user-attachments/assets/c160bbe4-4da1-416a-8a95-5ad446a19343)

![Image](https://github.com/user-attachments/assets/3d7fe27e-7889-4f8e-a006-d864758667a5)

---

# ü§ñ Propuesta de Proyecto: Sistema Inteligente de Monitoreo Ambiental (SIMA)

------------

## a) Propuesta de Proyecto

El proyecto SIMA (Sistema Inteligente de Monitoreo Ambiental) busca abordar la problem√°tica de la gesti√≥n y prevenci√≥n de desastres ambientales (como inundaciones o deslizamientos) mediante la implementaci√≥n de una infraestructura de IA robusta y descentralizada.

Utilizaremos el stack aprendido en Digitales III:

- Identificaci√≥n y Localizaci√≥n: Se emplear√° YOLO (You Only Look Once), entrenado con OpenCV, para identificar en tiempo real patrones de riesgo en im√°genes satelitales o de drones (e.g., cambios en el cauce de r√≠os, deforestaci√≥n, grietas en el suelo).

- Contenedorizaci√≥n y Despliegue: La aplicaci√≥n de IA, incluyendo el modelo YOLO y el servicio web, se empaquetar√° en contenedores Docker. Esto asegura la portabilidad y escalabilidad en la infraestructura de la convocatoria.

- Interfaz de Usuario: La visualizaci√≥n de alertas e informaci√≥n geogr√°fica (mapas de calor de riesgo, ubicaci√≥n de sensores) se realizar√° mediante una interfaz web desarrollada con Streamlit, facilitando la apropiaci√≥n social del conocimiento por parte de las organizaciones locales.

- Control de Versiones y Colaboraci√≥n: Todo el c√≥digo fuente, modelos y documentaci√≥n (README) se gestionar√°n en GitHub para garantizar la trazabilidad y la colaboraci√≥n entre los actores de la alianza.

- Sistema Operativo Base: Se utilizar√° Ubuntu como sistema operativo en los servidores y entornos de desarrollo/despliegue, aprovechando su estabilidad y soporte en la comunidad de c√≥digo abierto.

---

## üåç b) Sistema Inteligente de Monitoreo Ambiental (SIMA) - Convocatoria MinCiencias
### Infraestructura IA para la Resiliencia Territorial

[![Estado del Proyecto](https://img.shields.io/badge/Estado-En%20Desarrollo-blue)](README.md)
[![Licencia](https://img.shields.io/badge/Licencia-MIT-green)](LICENSE)

### üöÄ Resumen del Proyecto

SIMA es una soluci√≥n de Inteligencia Artificial orientada a fortalecer la **resiliencia territorial** ante los desaf√≠os del **cambio clim√°tico**. El proyecto propone una **infraestructura robusta** para el monitoreo predictivo de riesgos ambientales, transformando datos geoespaciales en alertas accionables.

| Componente Clave | Tecnolog√≠a Principal | Prop√≥sito |
| :--- | :--- | :--- |
| **Visi√≥n por Computadora** | **YOLOv8** & **OpenCV** | Detecci√≥n de anomal√≠as y patrones de riesgo (e.g., deslizamientos, inundaciones). |
| **Infraestructura** | **Docker** & **Ubuntu** | Contenedorizaci√≥n para un despliegue √°gil y escalable. |
| **Interfaz de Usuario** | **Streamlit** | Dashboard interactivo para la visualizaci√≥n de alertas y mapas de riesgo. |
| **Gesti√≥n de C√≥digo** | **GitHub** | Control de versiones, trazabilidad y colaboraci√≥n acad√©mica/empresarial. |

---

### üèõÔ∏è Arquitectura del Sistema

La arquitectura sigue un patr√≥n modular y distribuido, ideal para la infraestructura de IA:

| Etapa | M√≥dulo | Descripci√≥n |
| :---: | :---: | :--- |
| **1. Adquisici√≥n de Datos** | **M√≥dulo Geo-Data** | Captura de im√°genes satelitales (fuentes abiertas/p√∫blicas) y datos de sensores IoT. |
| **2. Procesamiento** | **M√≥dulo de Preprocesamiento** | Normalizaci√≥n de im√°genes y etiquetado de datos (usando scripts Python en **Ubuntu**). |
| **3. Inferencia IA** | **M√≥dulo de Detecci√≥n YOLO** | Contenedor **Docker** con el modelo **YOLO/OpenCV** para la identificaci√≥n de riesgos. |
| **4. Alerta y Visualizaci√≥n** | **M√≥dulo Streamlit** | Interfaz web que recibe las detecciones y las muestra en mapas georreferenciados. |

**Diagrama de Bloques Conceptual**

graph TD
    A[Datos Satelitales/IoT] --> B(Procesamiento de Datos);
    B --> C{Contenedor Docker: YOLO/OpenCV};
    C --> D(Base de Datos de Alertas);
    D --> E[Streamlit Dashboard];
    E --> F[Usuarios Finales/Organizaciones Locales];
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style E fill:#ccf,stroke:#333,stroke-width:2px

**Nota:** Este diagrama conceptual de flujo de datos se implementar√° usando las capacidades de contenerizaci√≥n de **Docker**.

---

### ‚öôÔ∏è Instrucciones de Despliegue (Docker y Ubuntu)

Para replicar este proyecto se requiere:

1.  Clonar el repositorio: `git clone https://github.com/tu-usuario/SIMA.git`
2.  Construir la imagen de Docker: `docker build -t sima-ia .`
3.  Ejecutar el contenedor en el servidor **Ubuntu**: `docker run -p 8501:8501 sima-ia`

El dashboard de **Streamlit** estar√° disponible en el puerto `8501`.

---
