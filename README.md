# üñºÔ∏è 1. An√°lisis de Sentimientos por Im√°genes con MediaPipe, Hilos, Mutex y Sem√°foros

Este componente implementa un sistema de clasificaci√≥n de **emociones b√°sicas** (feliz, triste, enojado) a partir de im√°genes faciales. Para la detecci√≥n y extracci√≥n de caracter√≠sticas, se utiliza la librer√≠a **MediaPipe Face Mesh**.

El procesamiento es **paralelo**, donde cada imagen se analiza en un **hilo independiente**, y el acceso a recursos compartidos se sincroniza mediante `Lock` y `Semaphore`.

---

### üéØ Objetivo de la Secci√≥n

Desarrollar un sistema concurrente capaz de:

1.  **Detectar rostros** en im√°genes usando **MediaPipe Face Mesh**.
2.  **Extraer *landmarks*** faciales relevantes (puntos clave). 
3.  **Inferir el sentimiento** (feliz, triste, enojado) utilizando reglas geom√©tricas simples basadas en los *landmarks* extra√≠dos.
4.  **Procesar m√∫ltiples im√°genes simult√°neamente** mediante hilos para optimizar el rendimiento.

| Mecanismo de Concurrencia | Prop√≥sito |
| :--- | :--- |
| **Hilos** (`threading.Thread`) | Procesamiento de cada imagen en paralelo. |
| **Mutex** (`Lock`) | Proteger la estructura de resultados compartida. |
| **Sem√°foro** (`Semaphore`) | Limitar el n√∫mero de im√°genes procesadas al mismo tiempo, controlando la carga del sistema. |

### ‚öôÔ∏è Instalaci√≥n y Ejecuci√≥n

Las dependencias principales para este entregable son
- opencv-python
- mediapipe
- numpy


## Esquema de Procesamiento Paralelo

| Etapa 1: Entrada | Etapa 2: Procesamiento (Hilos Paralelos) | Etapa 3: Salida Unificada |
| :---: | :---: | :---: |
| **[Imagen A]** | $\rightarrow$ **[Hilo 1]** | \ |
| **[Imagen B]** | $\rightarrow$ **[Hilo 2]** | $\rightarrow$ **[Resultados finales protegidos con Lock]** |
| **[Imagen C]** | $\rightarrow$ **[Hilo 3]** | / |

---
### üß† L√≥gica del Procesamiento

La clasificaci√≥n de emociones se basa en el an√°lisis de *landmarks* faciales extra√≠dos por MediaPipe, siguiendo una serie de pasos concurrentes:

---

- #### 1. Detecci√≥n del Rostro

Se utiliza la soluci√≥n de **MediaPipe Face Mesh** para identificar la posici√≥n y los 468 *landmarks* (puntos clave) del rostro en la imagen:

```bash
mp.solutions.face_mesh.FaceMesh
```
-Regla de Salida: Si el proceso no detecta un rostro en la imagen de entrada, el resultado inmediato es: ‚ÄúSIN ROSTRO DETECTADO‚Äù.

- #### 2. Landmarks Utilizados para Clasificaci√≥n

Para inferir la emoci√≥n, el sistema se enfoca en las m√©tricas geom√©tricas de las siguientes √°reas faciales, ya que son las m√°s expresivas de las emociones b√°sicas:

    Comisuras de la boca

    Apertura y curvatura de la boca

    √Ångulo de inclinaci√≥n de las cejas

    Relaci√≥n vertical entre los labios
    
#### 3. Reglas de Sentimientos (Clasificaci√≥n B√°sica)

La inferencia de la emoci√≥n se realiza aplicando **reglas geom√©tricas simples** (umbrales) sobre los *landmarks* extra√≠dos.

| Emoci√≥n | Patr√≥n Geom√©trico (Resumen) |
| :--- | :--- |
| **Feliz** | Boca m√°s ancha que alta, con **comisuras elevadas** (arqueadas hacia arriba). |
| **Triste** | Boca angosta y **comisuras ca√≠das** (arqueadas hacia abajo). |
| **Enojado** | **Ojos entrecerrados** y **cejas inclinadas** hacia el centro (fruncidas). |


- ### üßµ Concurrencia Implementada

Los mecanismos de concurrencia aseguran que el an√°lisis intensivo de im√°genes (MediaPipe) se ejecute de forma **paralela y segura**. 

| Mecanismo | C√≥digo de Implementaci√≥n | Funci√≥n |
| :--- | :--- | :--- |
| **‚úî Creaci√≥n de Hilos** | `t = threading.Thread(target=procesar_imagen, args=(ruta,))`<br>`t.start()` | Cada imagen de entrada lanza un **hilo independiente** para su procesamiento. |
| **‚úî Sem√°foro** | `semaforo = Semaphore(2)` | Limita el procesamiento a un m√°ximo de **2 hilos** (im√°genes) simult√°neamente, evitando la saturaci√≥n del sistema. |
| **‚úî Mutex** | `with lock:`<br>`resultados[ruta] = emocion` | Protege el **diccionario de resultados** (`resultados`), previniendo que m√∫ltiples hilos escriban o corrompan los datos al mismo tiempo (**condici√≥n de carrera**). |

####  Ejecuci√≥n

Para iniciar la aplicaci√≥n 
```bash
python "nombre".py
```
(Se deben tener preparadas las imagenes dentro de la carpeta para que logre procesarlas)

- #### üìä Ejemplo de Salida

```bash
Imagen_feliz.jpg   ‚Üí   Feliz
rostro_3.jpg       ‚Üí   Enojado
selfie.png         ‚Üí   SIN ROSTRO DETECTADO
```

- #### ‚úî Estado final de la secci√≥n

La soluci√≥n completa incluye:

Procesamiento por hilos ‚úî

Uso de sem√°foro ‚úî

Protecci√≥n con mutex ‚úî

MediaPipe para detecci√≥n facial ‚úî

Clasificaci√≥n de tres emociones (feliz, triste, enojado) ‚úî

---

![Image](https://github.com/user-attachments/assets/22ef69cf-dfdb-4cf8-b313-75174b84a129)

![Image](https://github.com/user-attachments/assets/fc167f04-2245-4811-a680-85c0e4c9023f)


---

# 2) üìò Desarrollo de un ETL partiendo de una base de datos

---

### üéØ Objetivo del Punto 2

El objetivo es desarrollar un pipeline ETL funcional, entrenar un modelo simple y desplegar un dashboard interactivo en Streamlit, integrando diferentes conceptos del curso.

Espec√≠ficamente, se busca:

* Desarrollar un **ETL completo** a partir de la base de datos proporcionada en clase (o datos sint√©ticos en caso de ausencia).
* Aplicar **transformaciones**, generar un dataset procesado.
* Construir un **dashboard con Streamlit** que visualice la informaci√≥n obtenida y los resultados del modelo.
  
### üìä Descripci√≥n del Dashboard (Resumen Funcional)

- El dashboard desarrollado en este punto ofrece una interfaz interactiva que permite visualizar y analizar los datos resultantes del proceso ETL. Entre sus funcionalidades principales se encuentran:

    - Visualizaci√≥n del dataset procesado: muestra las primeras filas del archivo procesado.csv, permitiendo revisar el estado final de los datos despu√©s de la limpieza y transformaci√≥n.

    - Mapa de correlaci√≥n: genera una matriz gr√°fica interactiva que permite identificar relaciones entre las variables num√©ricas del conjunto de datos.

    - Exploraci√≥n de distribuciones: ofrece la posibilidad de seleccionar cualquier variable num√©rica y visualizar su distribuci√≥n mediante un histograma.

    - Predicci√≥n con el modelo entrenado: permite cargar autom√°ticamente el modelo generado en el entrenamiento y realizar una predicci√≥n utilizando la primera fila del dataset, mostrando el valor calculado en la interfaz         lateral.

    - Indicadores de estado: el dashboard valida la presencia del dataset procesado y del modelo entrenado, mostrando advertencias si alguno de ellos no est√° disponible.

    - Este panel integra de forma pr√°ctica el resultado del ETL, el modelo de predicci√≥n y las herramientas de visualizaci√≥n, permitiendo analizar el comportamiento del sistema STC de manera clara e interactiva.


#### Conceptos Integrados

Este punto integra y refuerza conceptos clave vistos a lo largo del laboratorio:

* Terminal de **Ubuntu Linux**
* **Concurrencia / hilos / sem√°foros**
* **Seguridad en la red** (nmap, lynis)
* **Entornos virtuales** (`venv`)
* **Docker** para despliegue
* Uso de librer√≠as como Mediapipe y PyBullet (conceptos relacionados a visi√≥n/simulaci√≥n)
* **Arquitectura modular** en Python

---

### üìå Descripci√≥n del Trabajo Realizado

Durante este punto del laboratorio se desarroll√≥ una soluci√≥n modular, compuesta por un pipeline de datos y una capa de visualizaci√≥n:

## üßπ Explicaci√≥n Detallada del Proceso ETL Realizado

Este apartado responde a la pregunta del profesor sobre **‚Äúqu√© se hizo con los datos, c√≥mo se limpiaron y qu√© criterios se aplicaron en el procesamiento‚Äù**.

---

### 1. ¬øQu√© datos conten√≠a la base original?

La base de datos (archivo Excel de la tesis **‚ÄúS√≠ndrome de T√∫nel Carpiano‚Äù**) conten√≠a:

* **Se√±ales capturadas por sensores** (EMG, fuerza, aceler√≥metros, etc.).
* Informaci√≥n de **participantes**.
* Registros por **ensayo**.
* **Tiempos y valores** por cada movimiento.
* **Etiquetas** del experimento (**normal / patol√≥gico**).

> El archivo estaba dividido en **varias hojas** y ten√≠a **formatos no uniformes**.

---

## üìå 2. Principales problemas encontrados en la base de datos cruda

Durante la implementaci√≥n del ETL se identificaron varios *issues* t√≠picos:

* **‚ùå Formato inconsistente**
    * Algunas hojas ten√≠an encabezados distintos.
    * Los nombres de columnas no segu√≠an un mismo patr√≥n.
* **‚ùå Valores nulos o incompletos (`NaN`)**
    * En varias columnas de se√±ales aparec√≠an celdas vac√≠as.
    * Registros incompletos por fallas en el sensor.
* **‚ùå Variables irrelevantes**
    * Hab√≠a columnas que no aportaban al an√°lisis (comentarios, c√≥digos internos, *timestamps* redundantes).
* **‚ùå Datos num√©ricos sin normalizar**
    * Rango de sensores distinto entre pruebas.
    * Se√±ales sin escalar: **imped√≠an modelos de ML**.

---

## üìå 3. E ‚Äî Extract (Extracci√≥n)

El script de ETL realiz√≥ los siguientes pasos de extracci√≥n:

1.  **Ley√≥ todas las hojas del Excel** usando `pandas.read_excel()`.
2.  **Unific√≥** los *datasets* en un solo `DataFrame`.
3.  **Extrajo √∫nicamente las columnas relevantes**:
    * Se√±ales fisiol√≥gicas
    * Fuerzas y aceleraciones
    * Etiqueta (diagn√≥stico)
    * ID del paciente

> Se construy√≥ un solo *dataset* maestro llamado **`bd_completa`**.

## üìå 4. T ‚Äî Transform (Transformaci√≥n)

Las transformaciones aplicadas fueron:

- ‚úî Limpieza de filas vac√≠as
```bash
df = df.dropna()
```
- ‚úî Correcci√≥n de tipos de datos

    - Se forz√≥ a float32 todas las columnas de se√±ales.

    - Se eliminaron columnas con strings innecesarios.

- ‚úî Normalizaci√≥n MinMax por sensor

    - Esto es esencial para modelos neuronales:
```bash
scaler = MinMaxScaler()
df[numericas] = scaler.fit_transform(df[numericas])
```
- ‚úî Renombrado coherente de columnas

    - Para evitar errores posteriores en el modelo.

- ‚úî Eliminaci√≥n de duplicados
```bash
df = df.drop_duplicates()
```
- ‚úî Creaci√≥n de una columna de √≠ndice normalizado

    - Facilita el acceso desde el dashboard.

## üìå 5. L ‚Äî Load (Carga)

Finalmente, el ETL gener√≥:
```bash
data/procesado.csv
```

- Este archivo es:

    - Limpio

    - Normalizado

    - Cohesivo

    - Consistente en nombres y tipos

    - Sin duplicados

    - Listo para an√°lisis y para alimentar el modelo neuronal

El dashboard de Streamlit lo usa directamente.


#### ‚úî 1. Un Pipeline ETL Completo

El pipeline se divide en tres m√≥dulos esenciales para el procesamiento de datos:

| M√≥dulo | Funci√≥n | Descripci√≥n |
| :--- | :--- | :--- |
| **`extract`** | **Carga de Datos** | Carga de datos desde archivos fuente (Excel/CSV) o generaci√≥n de datos sint√©ticos. |
| **`transform`** | **Limpieza y Normalizaci√≥n** | Aplicaci√≥n de reglas de negocio, limpieza de *outliers* y normalizaci√≥n de variables. |
| **`load`** | **Exportaci√≥n** | Exportaci√≥n del dataset transformado a un archivo `procesado.csv` para su uso posterior. |

El ETL se ejecuta mediante el siguiente comando:

```bash
python3 etl_pipeline.py
```

**‚úî 2. Entrenamiento de un modelo b√°sico**

Utilizando redes neuronales con Keras/TensorFlow:

- Normalizaci√≥n MinMaxScaler

- Red sencilla (64‚Äì32‚Äì1)

- Entrenamiento supervisado

- Guardado del modelo en model/modelo_exportado.h5

Se ejecuta con:

```bash
python3 model/train_model.py
```
**‚úî 3. Creaci√≥n del Dashboard en Streamlit**

El dashboard:

- Muestra el dataset procesado

- Genera un mapa de correlaci√≥n

- Permite visualizar distribuciones

- Carga el modelo entrenado

- Realiza predicciones sobre filas del dataset

El dashboard se ejecuta con:
```bash
streamlit run dashboard/app.py
```

### üß† Conceptos aplicados
---

**üü¶ Ubuntu Linux**

- Terminal, rutas absolutas y relativas

- Manejo de entornos virtuales

- Ejecuci√≥n de scripts Python

- Instalaci√≥n de librer√≠as del laboratorio

**üüß ETL**

- Separaci√≥n en m√≥dulos: extract, transform, load

- Manejo de errores (archivos corruptos, rutas inv√°lidas)

- Consolidaci√≥n en procesado.csv

**üü® Concurrencia, hilos y sem√°foros**

- Aunque no se aplican directamente al ETL, s√≠ se integran en:

- Manejo de carga de modelo

**üü• Seguridad en la red**
```bash
nmap -sV localhost
sudo lynis audit system
```
Aplicadas para:

- Evaluar seguridad del contenedor

- Revisar puertos expuestos del dashboard

**üü™ Docker**

- Se prepar√≥ un Dockerfile para permitir:

- Instalar dependencias

- Ejecutar ETL, modelo y dashboard dentro de un contenedor

**üü© Machine Learning**

- Red neuronal artificial

- Normalizaci√≥n

- Entrenamiento supervisado

- Predicci√≥n desde el dashboard

**üü´ Mediapipe / PyBullet**

- Aunque no se usan directamente en el ETL, se relacionan con:

- Manejo de grandes vol√∫menes de datos sensoriales

- Comprensi√≥n de se√±ales biomec√°nicas

- Aplicaciones del curso

- Lectura concurrente de archivos (concepto discutido)

- Estructura del dashboard

---

### üìÇ Estructura del directorio

Descripci√≥n de M√≥dulos

    - data/

        BD_COMPLETA.xlsx: Base de datos original (opcional).

        sensores_base.csv: Datos base (Generados sint√©ticamente).

        procesado.csv: Dataset limpio y transformado (Salida del ETL).

    - etl/

        extract.py: M√≥dulo de Extracci√≥n (Carga de datos).

        transform.py: M√≥dulo de Transformaci√≥n (Limpieza y normalizaci√≥n).

        load.py: M√≥dulo de Carga (Exporta a procesado.csv).

        run_etl.py: Script principal de ejecuci√≥n del pipeline.

    - model/

        train_model.py: Script para el entrenamiento del modelo.

        predict_model.py: Script para predicciones.

        modelo_exportado.h5: Modelo entrenado y serializado.

    - dashboard/

        app.py: Dashboard interactivo con Streamlit (Punto 2).

    - tools/

        gen_synthetic.py: Script para generar datos sint√©ticos.
---

## üöÄ Procedimiento paso a paso

- 1Ô∏è‚É£ Crear entorno virtual

```bash
python3 -m venv venv
source venv/bin/activate
```

- 2Ô∏è‚É£ Instalar dependencias

```bash
    pip install -r requirements.txt
```

- 3Ô∏è‚É£ Generar datos sint√©ticos (opcional)

```bash
    python3 tools/gen_synthetic.py
```

- 4Ô∏è‚É£ Ejecutar ETL completo

```bash
    python3 etl/run_etl.py
```
Se genera:
```bash
    data/procesado.csv
```

- 5Ô∏è‚É£ Entrenar el modelo
```bash
    python3 model/train_model.py
```
Se genera:
```bash
    model/modelo_exportado.h5
```
- 6Ô∏è‚É£ Ejecutar dashboard
```bash
    streamlit run dashboard/app.py
```

### üìä Resultados esperados

- Archivo procesado.csv generado correctamente

- Modelo entrenado disponible

- Dashboard con:

    - visualizaci√≥n de la base procesada

    - mapa de correlaci√≥n

    - histogramas

    - predicci√≥n con modelo neuronal

### üß™ Validaci√≥n adicional 

Ver puertos expuestos:
```bash
    nmap -sV localhost
```

Auditor√≠a del sistema:
```bash
    sudo lynis audit system
```
--- 

# üê≥ Dockerizaci√≥n

Se realiz√≥ la **dockerizaci√≥n** del **ETL**, el **modelo** y el **dashboard** para garantizar **portabilidad**, **reproducibilidad** y **despliegue independiente** del sistema operativo.

A continuaci√≥n se describe el proceso realizado.

---

### üìå 1. Creaci√≥n del Dockerfile

Se cre√≥ un archivo `Dockerfile` en el directorio ra√≠z del proyecto.

### ¬øQu√© hace este Dockerfile?

* Utiliza una **imagen ligera** (`python:3.12-slim`).
* Copia **todo el proyecto** al contenedor.
* Instala **dependencias** sin utilizar cach√©.
* Expone el **puerto 8501** (donde corre Streamlit).
* Arranca directamente el **Dashboard** al iniciar el contenedor.

###  2. Construcci√≥n de la imagen

Desde la carpeta ra√≠z del proyecto:

```bash
    docker build -t stc_lab7 .
```
Donde:

- stc_lab7 es el nombre de la imagen resultante.

Esto genera una imagen autosuficiente que contiene:

- ETL

- Modelo

- Dashboard

- Dependencias de Python

-  3. Ejecuci√≥n del contenedor

Para ejecutar el dashboard desde Docker

```bash
    docker run -p 8501:8501 stc_lab7
```
Descripci√≥n:

- -p 8501:8501 expone el puerto del contenedor al host

- El dashboard queda disponible en:
    ```bash
    http://localhost:8501
    ```
    
###  4. Verificaci√≥n del despliegue

Despu√©s de levantar el contenedor:

‚úî Ver puertos activos con nmap
  ```bash
    nmap -sV localhost
   ```

Debe aparecer:
 ```bash
    8501/tcp open http streamlit
 ```
    
‚úî Auditor√≠a de seguridad opcional con lynix
  ```bash
sudo lynis audit system
  ```

- Esto valida:

    - dependencias del contenedor

    - puertos expuestos

    - vulnerabilidades conocidas

--- 

![Image](https://github.com/user-attachments/assets/86ae9d71-2f22-4654-a537-7bd19c0706f5)

![Image](https://github.com/user-attachments/assets/4b555cdf-5e0a-4aa6-b504-0ecd36eadbba)

![Image](https://github.com/user-attachments/assets/24a32a3c-eba4-4868-adf3-b549920acd65)

![Image](https://github.com/user-attachments/assets/4b6b32cc-e72a-4871-9d68-f62025598b45)

![Image](https://github.com/user-attachments/assets/7cf7f106-0c90-4d19-b969-b73633a8f523)

![Image](https://github.com/user-attachments/assets/502d65a6-a3af-4552-ba56-ef0e6c926db4)

![Image](https://github.com/user-attachments/assets/6ad58cea-81cf-4d2e-ad3d-2adc54db6886)

![Image](https://github.com/user-attachments/assets/c160bbe4-4da1-416a-8a95-5ad446a19343)

![Image](https://github.com/user-attachments/assets/3d7fe27e-7889-4f8e-a006-d864758667a5)

---

# ü§ñ Propuesta de Proyecto: Sistema Inteligente de Monitoreo Ambiental (SIMA)

------------

## a) Propuesta de Proyecto

El proyecto SIMA (Sistema Inteligente de Monitoreo Ambiental) busca abordar la problem√°tica de la gesti√≥n y prevenci√≥n de desastres ambientales (como inundaciones o deslizamientos) mediante la implementaci√≥n de una infraestructura de IA robusta y descentralizada.

Utilizaremos el stack aprendido en Digitales III:

- Identificaci√≥n y Localizaci√≥n: Se emplear√° YOLO (You Only Look Once), entrenado con OpenCV, para identificar en tiempo real patrones de riesgo en im√°genes satelitales o de drones (e.g., cambios en el cauce de r√≠os, deforestaci√≥n, grietas en el suelo).

- Contenedorizaci√≥n y Despliegue: La aplicaci√≥n de IA, incluyendo el modelo YOLO y el servicio web, se empaquetar√° en contenedores Docker. Esto asegura la portabilidad y escalabilidad en la infraestructura de la convocatoria.

- Interfaz de Usuario: La visualizaci√≥n de alertas e informaci√≥n geogr√°fica (mapas de calor de riesgo, ubicaci√≥n de sensores) se realizar√° mediante una interfaz web desarrollada con Streamlit, facilitando la apropiaci√≥n social del conocimiento por parte de las organizaciones locales.

- Control de Versiones y Colaboraci√≥n: Todo el c√≥digo fuente, modelos y documentaci√≥n (README) se gestionar√°n en GitHub para garantizar la trazabilidad y la colaboraci√≥n entre los actores de la alianza.

- Sistema Operativo Base: Se utilizar√° Ubuntu como sistema operativo en los servidores y entornos de desarrollo/despliegue, aprovechando su estabilidad y soporte en la comunidad de c√≥digo abierto.

---

## üåç b) Sistema Inteligente de Monitoreo Ambiental (SIMA) - Convocatoria MinCiencias
### Infraestructura IA para la Resiliencia Territorial

[![Estado del Proyecto](https://img.shields.io/badge/Estado-En%20Desarrollo-blue)](README.md)
[![Licencia](https://img.shields.io/badge/Licencia-MIT-green)](LICENSE)

### üöÄ Resumen del Proyecto

SIMA es una soluci√≥n de Inteligencia Artificial orientada a fortalecer la **resiliencia territorial** ante los desaf√≠os del **cambio clim√°tico**. El proyecto propone una **infraestructura robusta** para el monitoreo predictivo de riesgos ambientales, transformando datos geoespaciales en alertas accionables.

| Componente Clave | Tecnolog√≠a Principal | Prop√≥sito |
| :--- | :--- | :--- |
| **Visi√≥n por Computadora** | **YOLOv8** & **OpenCV** | Detecci√≥n de anomal√≠as y patrones de riesgo (e.g., deslizamientos, inundaciones). |
| **Infraestructura** | **Docker** & **Ubuntu** | Contenedorizaci√≥n para un despliegue √°gil y escalable. |
| **Interfaz de Usuario** | **Streamlit** | Dashboard interactivo para la visualizaci√≥n de alertas y mapas de riesgo. |
| **Gesti√≥n de C√≥digo** | **GitHub** | Control de versiones, trazabilidad y colaboraci√≥n acad√©mica/empresarial. |

---

### üèõÔ∏è Arquitectura del Sistema

La arquitectura sigue un patr√≥n modular y distribuido, ideal para la infraestructura de IA:

| Etapa | M√≥dulo | Descripci√≥n |
| :---: | :---: | :--- |
| **1. Adquisici√≥n de Datos** | **M√≥dulo Geo-Data** | Captura de im√°genes satelitales (fuentes abiertas/p√∫blicas) y datos de sensores IoT. |
| **2. Procesamiento** | **M√≥dulo de Preprocesamiento** | Normalizaci√≥n de im√°genes y etiquetado de datos (usando scripts Python en **Ubuntu**). |
| **3. Inferencia IA** | **M√≥dulo de Detecci√≥n YOLO** | Contenedor **Docker** con el modelo **YOLO/OpenCV** para la identificaci√≥n de riesgos. |
| **4. Alerta y Visualizaci√≥n** | **M√≥dulo Streamlit** | Interfaz web que recibe las detecciones y las muestra en mapas georreferenciados. |

**Diagrama de Bloques Conceptual**

graph TD
    A[Datos Satelitales/IoT] --> B(Procesamiento de Datos);
    B --> C{Contenedor Docker: YOLO/OpenCV};
    C --> D(Base de Datos de Alertas);
    D --> E[Streamlit Dashboard];
    E --> F[Usuarios Finales/Organizaciones Locales];
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style E fill:#ccf,stroke:#333,stroke-width:2px

**Nota:** Este diagrama conceptual de flujo de datos se implementar√° usando las capacidades de contenerizaci√≥n de **Docker**.

---

### ‚öôÔ∏è Instrucciones de Despliegue (Docker y Ubuntu)

Para replicar este proyecto se requiere:

1.  Clonar el repositorio: `git clone https://github.com/tu-usuario/SIMA.git`
2.  Construir la imagen de Docker: `docker build -t sima-ia .`
3.  Ejecutar el contenedor en el servidor **Ubuntu**: `docker run -p 8501:8501 sima-ia`

El dashboard de **Streamlit** estar√° disponible en el puerto `8501`.

---

### c) Tecnolog√≠as Futuras Sugeridas

Como experto en la tem√°tica y bas√°ndote en lo aprendido en Digitales III, estas son las tecnolog√≠as futuras que sugiero para llevar el proyecto a un nivel superior, enfocadas en la infraestructura de IA y la eficiencia:

1. Orquestaci√≥n de Contenedores (Kubernetes - K8s):

- Por qu√©: Para gestionar un gran n√∫mero de contenedores Docker en un entorno de producci√≥n (infraestructura a gran escala de MinCiencias). Permite la auto-sanaci√≥n, el escalado autom√°tico de los m√≥dulos de inferencia (YOLO) y la gesti√≥n eficiente de recursos.

2. Modelos de Lenguaje de Gran Escala (LLM) con RAG para Asistencia en Desastres:

- Por qu√©: Integrar un LLM (entrenado con datos locales/regionales) con la arquitectura RAG (Retrieval-Augmented Generation). Esto permitir√≠a a los usuarios (organizaciones locales) consultar la base de datos de alertas en lenguaje natural (ej. "¬øHay riesgo de inundaci√≥n en el r√≠o X la pr√≥xima semana?").

3. Edge Computing y Microcontroladores para Sensores Remotos:

- Por qu√©: Implementar una versi√≥n muy ligera de la inferencia (Tiny-YOLO o modelos optimizados) directamente en dispositivos de bajo consumo (Raspberry Pi o ESP32) ubicados en zonas de riesgo, enviando solo las alertas cr√≠ticas. Esto reduce la latencia y la dependencia de la conexi√≥n a la nube para la toma de decisiones cr√≠ticas.

El siguiente video muestra la visi√≥n de MinCiencias sobre las convocatorias, lo que ayuda a contextualizar la importancia de la iniciativa Colombia Inteligente.

**https://www.youtube.com/watch?v=GlWUn2T3h5Y**

---

## üí° d) Conclusi√≥n e Impacto Socio-T√©cnico

### Conclusi√≥n y Alineaci√≥n

El Sistema Inteligente de Monitoreo Ambiental (SIMA) demuestra c√≥mo las tecnolog√≠as aprendidas en Digitales III (OpenCV, YOLO, Streamlit, Docker, y GitHub) forman una infraestructura de IA coherente y desplegable. La selecci√≥n de Docker es crucial, ya que garantiza la portabilidad de nuestro modelo (YOLO) a trav√©s de la infraestructura que la convocatoria de MinCiencias busca establecer, asegurando la repetibilidad y la escalabilidad del sistema en diversas regiones de Colombia.

---

### Impacto Social y Contribuci√≥n a la Convocatoria

El proyecto SIMA impacta directamente la misi√≥n de la convocatoria "Colombia Inteligente: Infraestructura para el Desarrollo de la Inteligencia Artificial" al:

1. Fomentar la Apropiaci√≥n Social: El uso de Streamlit permite crear un dashboard accesible que traduce la compleja detecci√≥n de riesgos por IA en informaci√≥n simple para los tomadores de decisiones locales, cumpliendo con el objetivo de democratizar el acceso a la tecnolog√≠a.

2. Mitigar Riesgos Ambientales: Al proporcionar alertas tempranas, el sistema reduce la vulnerabilidad de las comunidades ante eventos clim√°ticos extremos, contribuyendo a la resiliencia territorial y salvaguardando vidas y bienes.

3. Generaci√≥n de Datos: SIMA crea una fuente continua de datos etiquetados sobre patrones de riesgo, que puede ser utilizada por la infraestructura de MinCiencias para entrenar modelos de IA m√°s robustos a nivel nacional.

En esencia, el proyecto no solo utiliza la infraestructura de IA, sino que contribuye activamente a ella, proporcionando una aplicaci√≥n pr√°ctica y un modelo de datos valioso.
# üõ†Ô∏è Exploraci√≥n de Tecnolog√≠as de Infraestructura y Automatizaci√≥n

Para que el proyecto SIMA trascienda el entorno local y se integre eficientemente en la infraestructura de IA de MinCiencias, es imperativo dominar herramientas de aprovisionamiento, configuraci√≥n y mensajer√≠a.

## a) üåç Terraform: Infraestructura como C√≥digo (IaC)

Terraform, desarrollado por HashiCorp, es una herramienta agn√≥stica a la nube que permite a los equipos definir y aprovisionar la infraestructura de un centro de datos o de proveedores de nube (AWS, Azure, Google Cloud, OpenStack) mediante archivos de configuraci√≥n declarativos.

| Caracter√≠stica Clave | Descripci√≥n | Beneficio para SIMA |
|----------------------|-------------|----------------------|
| Declarativo | Define el estado final deseado de la infraestructura (ej. "Quiero una m√°quina virtual, un bucket de almacenamiento y una red"). | Predecibilidad: Asegura que los entornos de desarrollo, prueba y producci√≥n sean id√©nticos, eliminando errores de configuraci√≥n manual. |
| Proveedores | Soporta una vasta cantidad de providers (m√°s de 1000) que van desde nubes p√∫blicas hasta servicios SaaS y soluciones on-premise (como OpenStack). | Portabilidad: Permite migrar o replicar el entorno de IA de SIMA (VMs, redes, balanceadores) en cualquier nube que se exija en la convocatoria. |
| Planificaci√≥n | Utiliza los comandos `plan` y `apply`. El plan muestra exactamente qu√© recursos se crear√°n, modificar√°n o destruir√°n antes de ejecutar. | Seguridad: Permite revisar y auditar los cambios de infraestructura antes de aplicarlos, minimizando el riesgo de interrupciones o costos inesperados. |
| Lenguaje (HCL) | Utiliza el HashiCorp Configuration Language (HCL), que es legible por humanos y f√°cil de aprender. | Legibilidad: Facilita la colaboraci√≥n y la revisi√≥n por pares del c√≥digo de infraestructura. |

---

### b) ‚öôÔ∏è Ansible: Automatizaci√≥n de la Configuraci√≥n

Ansible, una herramienta de automatizaci√≥n open source mantenida por Red Hat, se enfoca en la gesti√≥n de la configuraci√≥n, el despliegue de aplicaciones y la orquestaci√≥n.

| Caracter√≠stica Clave | Descripci√≥n | Beneficio para SIMA |
|----------------------|-------------|----------------------|
| Agente Less | No requiere software o agentes especiales instalados en las m√°quinas gestionadas. Utiliza SSH para la comunicaci√≥n (en sistemas Linux/Ubuntu) y PowerShell/WinRM (en Windows). | Simplicidad: Reduce la sobrecarga y los puntos de fallo, siendo ideal para configurar r√°pidamente el entorno Ubuntu de los servidores. |
| Playbooks (YAML) | Las tareas se definen en archivos YAML llamados Playbooks, que son f√°ciles de leer y escribir. | Claridad: Permite definir la secuencia de pasos para instalar dependencias de Python, Docker y el modelo YOLO de forma estandarizada. |
| Idempotencia | La ejecuci√≥n de un Playbook siempre lleva el sistema al estado deseado, independientemente de su estado inicial. Si una dependencia ya est√° instalada, Ansible no intentar√° instalarla de nuevo. | Fiabilidad: Asegura que la configuraci√≥n de cada nodo del cluster de IA sea exactamente la misma, sin duplicidades. |
| Integraci√≥n IaC | Se utiliza com√∫nmente despu√©s de aprovisionar la infraestructura con Terraform para realizar la configuraci√≥n inicial. | Flujo DevOps: Permite un flujo continuo: Terraform crea la VM ‚Üí Ansible instala el software y despliega el contenedor Docker. |

---

### c) üêá RabbitMQ: Mensajer√≠a As√≠ncrona Robusta (Broker)

RabbitMQ es un broker de mensajes open source basado en el est√°ndar AMQP (Advanced Message Queuing Protocol). Su funci√≥n principal es desacoplar las aplicaciones, permitiendo que se comuniquen de forma as√≠ncrona.

| Concepto    | Rol en la Arquitectura | Beneficio para SIMA |
|-------------|-------------------------|----------------------|
| Broker | El servidor central que recibe, almacena y env√≠a mensajes. | Fiabilidad: Los mensajes se almacenan hasta que el consumidor los procesa, evitando la p√©rdida de alertas cr√≠ticas (detecciones de YOLO) si el servidor de Streamlit est√° ca√≠do. |
| Productor | El componente que env√≠a mensajes a una cola (ej. el M√≥dulo de Detecci√≥n YOLO). | Desacoplamiento: El m√≥dulo YOLO solo necesita saber d√≥nde enviar la alerta, sin preocuparse si el dashboard de Streamlit est√° escuchando en ese momento. |
| Consumidor | El componente que recibe y procesa mensajes de una cola (ej. el M√≥dulo Streamlit/Base de Datos). | Escalabilidad: Se pueden a√±adir m√∫ltiples consumidores (ej. un servicio que env√≠a emails y otro que actualiza la BD) sin modificar el c√≥digo del productor (YOLO). |
| Asincron√≠a | La comunicaci√≥n no requiere una respuesta inmediata. | Eficiencia: El procesamiento de im√°genes pesadas de YOLO no bloquea el env√≠o inmediato de la alerta, acelerando el tiempo de respuesta del sistema. |

---

### d) ‚òÅÔ∏è Tecnolog√≠as OpenStack para la Generaci√≥n de Nubes Propias

OpenStack es un conjunto de herramientas de software open source para construir y gestionar plataformas de cloud computing para nubes p√∫blicas y privadas. Es la alternativa open source a AWS, Azure o Google Cloud, esencial para infraestructuras soberanas o privadas (como podr√≠a ser un cluster dedicado de MinCiencias).

| Componente Clave | Funci√≥n Principal | Analog√≠a en la Nube P√∫blica |
|------------------|-------------------|------------------------------|
| Nova | Proporciona el servicio de Computaci√≥n. Gesti√≥n de M√°quinas Virtuales (VMs) y contenedores. | EC2 (AWS), Compute Engine (GCP) |
| Swift / Cinder | Proporcionan servicios de Almacenamiento de Objetos (Swift) y de Bloques (Cinder) para VMs. | S3 (AWS), Persistent Disk (GCP) |
| Neutron | Ofrece el servicio de Redes. Permite a los usuarios crear redes virtuales, routers y direcciones IP. | VPC (AWS), Virtual Network (Azure) |
| Keystone | Proporciona el servicio de Identidad y Acceso. Gestiona usuarios, roles y permisos de los proyectos. | IAM (AWS), Cloud IAM (GCP) |

---

## Relevancia para la Convocatoria de MinCiencias:

Si la infraestructura de la convocatoria no se basa puramente en nubes comerciales, sino en un cluster de c√≥mputo propio (Cloud Privada o H√≠brida) dentro de una entidad p√∫blica o universidad, es altamente probable que est√© gestionada por OpenStack. Conocer OpenStack asegura que los ingenieros puedan aprovisionar recursos de IA (VMs con GPUs para YOLO) y configurar las redes necesarias para la comunicaci√≥n de RabbitMQ utilizando est√°ndares abiertos.

---

## üîó Integraci√≥n y Orquestaci√≥n: De IaC al Contenedor

La eficiencia en el despliegue de soluciones de Inteligencia Artificial (IA) en entornos de producci√≥n (como el propuesto por la convocatoria) se logra mediante la automatizaci√≥n completa del ciclo de vida de la infraestructura y el software.

La siguiente secuencia describe un flujo continuo donde Terraform, Ansible, y Docker act√∫an de forma concertada para desplegar y configurar el Sistema Inteligente de Monitoreo Ambiental (SIMA).

### 1. ‚öôÔ∏è Etapa 1: Aprovisionamiento de la Infraestructura con Terraform (IaC)

El proceso inicia con la definici√≥n del hardware y la red necesarios para alojar los m√≥dulos de IA.

- Acci√≥n de Terraform: Usando archivos .tf escritos en HCL, Terraform se comunica con el proveedor de la nube (ej. OpenStack o la nube elegida por MinCiencias) y ejecuta el comando terraform apply.

- Recursos Creados para SIMA:

- - M√°quinas Virtuales (VMs) de C√≥mputo: Crea dos o m√°s instancias de VM (basadas en Ubuntu), posiblemente con aceleradores gr√°ficos (GPU) para el M√≥dulo de Detecci√≥n YOLO.

- - Base de Datos y Broker: Aprovisiona instancias dedicadas para la base de datos de alertas y para el servidor de mensajer√≠a RabbitMQ.

- - Networking: Configura las subredes, reglas de firewall (puertos 22/SSH, 8501/Streamlit y 5672/RabbitMQ) y Balanceadores de Carga (para distribuir el tr√°fico a m√∫ltiples instancias de Streamlit).

Resultado: Se obtiene una infraestructura de red estable y replicable, con direcciones IP definidas para cada componente (VMs de Ubuntu).

---

### 2. üóÑÔ∏è Etapa 2: Configuraci√≥n y Preparaci√≥n con Ansible

Una vez que las VMs est√°n levantadas, Ansible toma el control para configurar el sistema operativo y preparar el entorno para la aplicaci√≥n. Ansible utiliza el inventario de IPs generado autom√°ticamente por Terraform.

- Playbook de Pre-requisitos: Ansible se conecta v√≠a SSH a las VMs de Ubuntu (sin necesidad de agentes) y ejecuta los siguientes playbooks:

- - Instalaci√≥n de utilidades base y configuraci√≥n de seguridad.

- - Instalaci√≥n del runtime de Docker en las VMs de YOLO y Streamlit.

- - Configuraci√≥n espec√≠fica del host (ej. montar vol√∫menes persistentes para los modelos de YOLO y los datos de entrenamiento).

- Playbook de Despliegue de Aplicaciones Secundarias:

- - Garantiza que el broker RabbitMQ est√© configurado y corriendo con las colas y usuarios correctos para el env√≠o de alertas.

Resultado: Las m√°quinas Ubuntu est√°n listas; tienen Docker instalado y el broker de mensajer√≠a ya est√° operativo, esperando los mensajes.

---

### 3. üì¶ Etapa 3: Despliegue de la Aplicaci√≥n con Docker

Ansible, como gestor de configuraci√≥n, tambi√©n puede iniciar el despliegue final de la aplicaci√≥n, aprovechando la portabilidad de los contenedores Docker.

- Rol del Contenedor: Ansible puede ejecutar comandos docker-compose o docker run en las VMs de Ubuntu.

- Despliegue de M√≥dulos SIMA:

- - Despliega el contenedor YOLO/OpenCV (Productor), el cual es un ejecutable aut√≥nomo. Este contenedor comienza a recibir im√°genes para el an√°lisis y a enviar mensajes de alerta al broker RabbitMQ.

- - Despliega el contenedor Streamlit (Consumidor), el cual se inicializa y se conecta a RabbitMQ para leer las alertas en tiempo real y mostrarlas en el dashboard.

Resultado: El sistema SIMA est√° completamente operativo y accesible, con todos sus m√≥dulos funcionando dentro de contenedores aislados y gestionados.

---

### 4. ‚úâÔ∏è El Rol Desacoplador de RabbitMQ

La integraci√≥n de RabbitMQ es vital en este pipeline de IA para garantizar la alta disponibilidad y el desacoplamiento de los m√≥dulos:

| Flujo de Informaci√≥n | Uso de RabbitMQ | Impacto Operacional |
|----------------------|------------------|----------------------|
| YOLO ‚Üí Streamlit | El m√≥dulo YOLO (Productor) publica un mensaje de "alerta de riesgo" en una cola. | Resiliencia: Si el servidor de Streamlit se reinicia, el mensaje permanece seguro en RabbitMQ y no se pierde, siendo procesado tan pronto como Streamlit se recupere. |
| Escalado | Se pueden a√±adir nuevas instancias de YOLO para aumentar la capacidad de procesamiento de im√°genes. | Simplicidad: Los nuevos productores solo necesitan la direcci√≥n del broker, sin afectar a los consumidores (Streamlit). |

Esta cadena de herramientas (Terraform $\rightarrow$ Ansible $\rightarrow$ Docker/RabbitMQ) representa el est√°ndar moderno de DevOps, permitiendo la velocidad, fiabilidad y escalabilidad necesarias para un proyecto de infraestructura de IA de MinCiencias.

---

## üìö Referencias

La informaci√≥n presentada en esta documentaci√≥n t√©cnica se fundamenta en los siguientes recursos especializados en Arquitectura de Sistemas, DevOps e Infraestructura como C√≥digo (IaC):

### 1. Infraestructura como C√≥digo (Terraform)

- HashiCorp. (2024). Terraform Documentation. Recuperado de: https://developer.hashicorp.com/terraform/docs

### 2. Automatizaci√≥n y Gesti√≥n de Configuraci√≥n (Ansible)

- Ansible Documentation. Introduction to Ansible. Recuperado de: https://docs.ansible.com/ansible/latest/user_guide/intro_getting_started.html

### 3. Mensajer√≠a As√≠ncrona (RabbitMQ)

- Videla, G. (2018). RabbitMQ Essentials: The Advanced Message Queuing Protocol (AMQP) in Practice. Packt Publishing.

### 4. Cloud Computing Open Source (OpenStack)

OpenStack Foundation. OpenStack Documentation: Project Navigator. Recuperado de: https://docs.openstack.org/
